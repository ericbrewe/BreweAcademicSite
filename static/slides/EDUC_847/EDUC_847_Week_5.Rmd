---
title: "EDUC 847 Winter 24"
subtitle: Week 5 - Multiple Regression
author: 'Eric Brewe <br> Professor of Physics at Drexel University <br>'
date: "5 February 2025, last update: `r Sys.Date()`"
output: 
  xaringan::moon_reader:
    css: [default, metropolis, "BreweSlides.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(janitor)
library(haven)
library(here)
library(broom)
library(mice)
library(car)
library(jtools)
library(kableExtra)
library(broom.mixed)
library(emdi)
library(interactions)

```





# Let's start with a complete dataset

Start by getting the data into R

```{r ReadDataforReal, echo=FALSE}

sci_df <- read_csv(here("static/slides/EDUC_847/data", "science_scores.csv"))

```


```{r ReadData, eval=FALSE}
#This loads the csv and saves it as a dataframe titled week_1_data

sci_df <- read_csv(here("data",
                        "science_scores.csv"))

```


---
# Let's remember last week

### We want to predict a science score from a math score. 
```{r LinearRegression}

sci_mod_math <- lm(sci ~ math_sc, data = sci_df) #<<

tidy(summary(sci_mod_math))
```

Note - we have a new dataset, nothing is missing!



---
# Let's use motivation in a model

```{r MotivMod, eval = FALSE }

sci_mod_motiv <- lm(sci ~ motiv, data = sci_df)

tidy(sci_mod_motiv)


```


```{r MotivMod2, echo=FALSE }

sci_mod_motiv <- lm(sci ~ motiv, data = sci_df)

tidy(summary(sci_mod_motiv))



```

---
# Let's reflect

```{r CompareModels}

tidy(sci_mod_math)


tidy(sci_mod_motiv)

```
---
# Let's reflect

We have two models that predict science score.

Which is right? 

Which is better?

---
# Let's try something new

What if we put them both in the model?

```{r Model_Math_Motiv }

sci_mod_motiv_math <- lm(sci ~ math_sc + motiv, data = sci_df)

tidy(sci_mod_motiv_math)


```



---
# Let's interpret
```{r MRLogTransformMod3, echo=FALSE }

summary(sci_mod_motiv_math)



```


---
# Let's interpret graphically

```{r AddedVariablePlots}

avPlots(sci_mod_motiv_math)


```


---
# Let's look at these coefficients

```{r CoefficientPlots}

plot_summs(sci_mod_motiv_math)


```



---
# Let's look at these coefficients

```{r CoefficientPlotsCI}

plot_summs(sci_mod_motiv_math, inner_ci_level = 0.9)


```
---
# Let's review the goodness of fit

```{r GoodnessOfFit}

glance(sci_mod_motiv_math)
```
This give us some numbers, but we need to know what these mean. 

---
# Let's decide, is it a better model?

We have a few options...

- Look at the 	$R^{2}$
- Look at the adjusted $R^{2}$
  - adj $R^{2} = 1 - \frac{SS_{res}}{SS_{tot}}*\frac{N-1}{N-K-1}$
- Akaike information criteria
  - $AIC = \frac{SS_{res}}{\sigma} + 2K$
    - ==Lower is better!==
  - to access AIC can use the step function in the emdi package
  

---
# Let's look at AIC


To do this, we start with the full model and remove variables and recalculate the AIC. This is called backward selection. 

```{r AIC_L, eval=FALSE}

step(sci_mod_motiv_math, 
     direction = "backward")

```


---
# Let's look at AIC


```{r AIC_R, echo=FALSE}

step(sci_mod_motiv_math, direction = "backward")


```


---
# Let's compare models graphically

```{r CompareModelsGr}

plot_summs(sci_mod_motiv, sci_mod_motiv_math, inner_ci_level = 0.9)
```

---
# Let's compare statistically

We saw that the AIC went down, but more complicated models are typically worse (prone to overfitting, harder to interpret, etc...) Is there a way to compare the models statistically so we can decide if it is worth it to use the more complicated model. We will compare with an ANOVA

We will compare the model with the motivation score as compared to the model with just the math score.


```{r AnovaModels}

anova(sci_mod_math, sci_mod_motiv_math)

```


---
# Let's try more variables

What about the group variable? Maybe some groups differ on math, motivation, and science score...

```{r sci_mod_math_motiv_group}

sci_mod_motiv_math_gr <- lm(sci~ math_sc + motiv + gr , data = sci_df)

tidy(sci_mod_motiv_math_gr)
```


---
# Let's try more variables

What about the group variable? Maybe some groups differ on math, motivation, and science score...

```{r sci_mod_math_motiv_group_graph}

plot_summs(sci_mod_motiv, 
           sci_mod_motiv_math, 
           sci_mod_motiv_math_gr, inner_ci_level = 0.9)
```

---
# Let's dummy code

So, the main idea here is that we can see that group might matter...but we don't know which group. So let's set up separate variables for each group. 

```{r DummyCoding}

sci_df %>%
  mutate(Gr1 = case_when(gr == 1 ~ 1, 
                         gr != 1 ~0))  %>%
  head(., 20)
```


---
# Let's dummy code

Now extend out to all groups and assign to new dataframe

```{r DummyCoding2}

sci_df %>%
  mutate(Gr1 = case_when(gr == 1 ~ 1, 
                         gr != 1 ~0))  %>%
  mutate(Gr2 = case_when(gr == 2 ~ 1, 
                         gr != 2 ~0)) %>%
  mutate(Gr3 = case_when(gr == 3 ~ 1, 
                         gr != 3 ~0)) %>%
  mutate(Gr4 = case_when(gr == 4 ~ 1, 
                         gr != 4 ~0)) %>%
  mutate(Gr5 = case_when(gr == 5 ~ 1, 
                         gr != 5 ~0)) -> sci_df_groups

```

---
# Let's include the groups in a model

Need to use the new dataframe and add all the different groups

```{r sci_mod_motiv_math_groups}

sci_mod_motiv_math_groups <- lm(sci~ math_sc + 
                                     motiv + 
                                     Gr1 +
                                     Gr2 +
                                     Gr3 +
                                     Gr4 +
                                     Gr5 , data = sci_df_groups)
```


---
# Let's include the groups in a model

```{r sci_mod_motiv_math_groups_summary}

summary(sci_mod_motiv_math_groups)


```



---
# Let's explore interactions

What if a student's motivation is somehow connected to their math score?

We should look for interactions...

```{r Interactions}
sci_mod_motiv_math_interactions <- lm(sci~ math_sc*motiv , data = sci_df)

summary(sci_mod_motiv_math_interactions)

```
---
# Let's plot this...

There are two ways, first, we can plot out the coefficients like we have done before...

```{r InteractionsPlot1 }

plot_summs(sci_mod_motiv_math_interactions, inner_ci_level = 0.9)

```

---
# Let's plot this...

There are two ways, or we can use the interact_plot

```{r InteractionsPlot2 }

interact_plot(model = sci_mod_motiv_math_interactions, pred =  math_sc, modx = motiv)

```

---
# Let's review...

We spent today looking at how to do multiple regression

We can...
 - run a multiple regression
 - interpret a multiple regression 
 - consider categorical variables
 - dummy code for categorical variables
 - visualize regression coefficients
 - handle interaction terms