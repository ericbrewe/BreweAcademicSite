---
title: "EDUC 847 Winter 24"
subtitle: Week 5 - Multiple Regression
author: 'Eric Brewe <br> Professor of Physics at Drexel University <br>'
date: "12 February 2024, last update: `r Sys.Date()`"
output: 
  xaringan::moon_reader:
    css: [default, metropolis, "BreweSlides.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(janitor)
library(haven)
library(here)
library(broom)
library(mice)
library(car)

```





# Let's start with a complete dataset

Start by getting the data into R

```{r ReadDataforReal, echo=FALSE}

sci_df <- read_csv(here("static/slides/EDUC_847/data", "science_scores2_Complete.csv"))

```


```{r ReadData, eval=FALSE}
#This loads the csv and saves it as a dataframe titled week_1_data

sci_df <- read_csv(here("data",
                        "science_scores2_Complete.csv"))

```


---
# Let's remember last week

### We want to predict a science score from a math score. 
```{r LinearRegression}

sci_mod_math <- lm(sci ~ math_sc, data = sci_df) #<<

summary(sci_mod_math)
```

Note - we have a new dataset, nothing is missing!

---
# Let's remember we transformed pre_sc

.pull-left[

```{r LogTrans, echo= FALSE}

sci_df %>%
  ggplot(aes(y =  log(pre_sc))) +
  geom_histogram() + 
  theme_minimal() + 
  coord_flip()
```

]

.pull-right[

```{r LogTransR, eval= FALSE}

sci_df %>%
  ggplot(aes(y = log(pre_sc))) +
  geom_histogram() + 
  theme_minimal() + 
  coord_flip()
```
]
---
# Let's use the log transform in a model

```{r LogTransformMod, eval = FALSE }

sci_mod_pre <- lm(sci ~ log(pre_sc), data = sci_df)

summary(sci_mod_pre)

```


```{r LogTransformMod2, echo=FALSE }

sci_mod_pre <- lm(sci ~ log(pre_sc), data = sci_df)

summary(sci_mod_pre)

```

---
# Let's reflect

```{r}

tidy(summary(sci_mod_math))

tidy(summary(sci_mod_pre))
```




---
# Let's put them both in the model

```{r MRLogTransformMod, eval = FALSE }

sci_mod_pre_math <- lm(sci ~ math_sc + log(pre_sc), data = sci_df)

summary(sci_mod_pre_math)

```


```{r MRLogTransformMod2, echo=FALSE }

sci_mod_pre_math <- lm(sci ~ math_sc + log(pre_sc), data = sci_df)

summary(sci_mod_pre_math)

```

---
# Let's interpret
```{r MRLogTransformMod3, echo=FALSE }

summary(sci_mod_pre_math)



```


---
# Let's interpret graphically

```{r AddedVariablePlots}

avPlots(sci_mod_pre_math)


```

---
# Let's decide, is it a better model?




We can do a histogram of residuals for transformed data

.pull-left[
```{r LogResidualHist, echo=FALSE }

log_sci_mod_df <- augment(Mod3)

log_sci_mod_df %>%
  ggplot(aes(y = .resid)) +
  geom_histogram() + 
  theme_minimal() + 
  coord_flip()


```

]
.pull-right[




```{r LogResidualCheck3, eval=FALSE}

log_sci_mod_df %>%
  ggplot(aes(y = .resid)) +
  geom_histogram() + 
  theme_minimal() + 
  coord_flip()

```
]



---
# Let's consider some other transforms

## Another common transformation is to use Z-scores
This makes it easy to compare coefficients

```{r ZScTransformMod }

Mod4 <- lm(scale(sci) ~ scale(math_sc), data = sci_df)

summary(Mod4)

```
Hey, notice that the t-value and the p value both stay the same as the first model!
---
# Let's deal with these missing data!

```{r}
summary(sci_df)

```


Any thoughts?

---
# Let's deal with these missing data!

## Here are some options

- Hot Deck Replacement
- Mean/Median Replacement
- Regression Replacement
- Multiple Imputation

---
# Let's look at the basics of Multiple Imputation
 
 - Impute missing data (do this several/a bunch of times)
 - Analyze all the new data sets
 - Pool the results
 
Sounds difficult, no?

---
# Let's try multiple imputation

## First, it works best with data that are MCAR or MAR

```{r visualizeMD}

md.pattern(sci_df)

```

---
# Let's go ahead and impute

First, we will set up a dataset with 5 iterations of the imputed data. 


```{r imputeMissingData}

sci_df_imp <- mice(sci_df, maxit = 5, m = 5, seed = 327)

```

---
# Let's plot our imputed data 

We should look at how the new data are distributed using a stripplot. 
```{r plotImputedMathScore}
stripplot(sci_df_imp, math_sc, xlab = "imputation number")
```


---
# Let's use this in a linear model

```{r ModelWithImputedData}

sci_mod_imp <- with(sci_df_imp, lm(sci~ math_sc))

summary(pool(sci_mod_imp))

```

---
# Let's review...

We spent more time dealing with the underlying data for linear modeling

We can...
 - transform data when it is not normally distributed
   - Log-Transform
   - Z-scores
 - visualize missingness in our dataset
 - use multiple imputation with chained equations. 